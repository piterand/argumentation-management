{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-approach",
   "metadata": {},
   "source": [
    "# Sentencizer\n",
    "https://spacy.io/usage/linguistic-features#sbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "assert doc.has_annotation(\"SENT_START\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"../data/Original/iued_test_original.txt\"\n",
    "#name = \"../data/Original/iued_test_original.vrt\"\n",
    "with open (name, \"r\") as myfile:\n",
    "    data=myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)\n",
    "assert doc.has_annotation(\"SENT_START\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde50776",
   "metadata": {},
   "source": [
    "This gives somewhat accurate results, with some errors after numbers. You can also use a trained model, however this will not work on uncommon texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9379e30",
   "metadata": {},
   "source": [
    "Also fails for the example here. Then there is the one based on a statistical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92539652",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.enable_pipe(\"senter\")\n",
    "doc = nlp(data)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b28c9",
   "metadata": {},
   "source": [
    "Directly use the sentencizer without the pipeline - this one looks at punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()  # just the language with no pipeline\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "doc = nlp(data)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b81e27",
   "metadata": {},
   "source": [
    "Seems to work correctly. What is the difference to the pipeline? In the DW scripts, the other components are disabled via the \"exclude\" command - should be faster as pipeline is not loaded at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for doc in nlp.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    # Do something with the doc here\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c752ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"tagger\", \"ner\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "for doc in nlp.pipe(texts):\n",
    "    for sent in doc.sents:\n",
    "        print(sent.text)\n",
    "        print('***') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0217e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0f812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1946ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca31d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d32cea49",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "https://spacy.io/usage/linguistic-features#tokenization  \n",
    "We need to allow for special case rules. \n",
    "```\n",
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
    "```\n",
    "\n",
    "Also, there are custom tokenizer libraries that one may want to load. Probably we would want to keep it so that users can specify their custom tokenizers in addition to the standard one from spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7cc315",
   "metadata": {},
   "source": [
    "# Lemmatizer\n",
    "https://spacy.io/usage/linguistic-features#lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "print(lemmatizer.mode)  # 'rule'\n",
    "doc = nlp(\"I was reading the paper.\")\n",
    "print([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)\n",
    "print([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d46ee9",
   "metadata": {},
   "source": [
    "Should punctuation be excluded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc49f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da57ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f663e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936093af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b36cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca13b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec81832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7996d52f",
   "metadata": {},
   "source": [
    "# POS tagger\n",
    "https://spacy.io/usage/linguistic-features#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c539fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1c396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352b174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b03cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083bb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9aa50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef38f8fb",
   "metadata": {},
   "source": [
    "# Morphology\n",
    "https://spacy.io/usage/linguistic-features#morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline:\", nlp.pipe_names)\n",
    "doc = nlp(\"I was reading the paper.\")\n",
    "token = doc[0]  # 'I'\n",
    "print(token.morph)  # 'Case=Nom|Number=Sing|Person=1|PronType=Prs'\n",
    "print(token.morph.get(\"PronType\"))  # ['Prs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62417153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5703ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c09da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a0821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ddb1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca38ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4febe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "170975a1",
   "metadata": {},
   "source": [
    "# Constituency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde5927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79e0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47151e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd32496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f3d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb6d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc60eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f4c91c3",
   "metadata": {},
   "source": [
    "# Collocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadd6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e02546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2eb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3e222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2927c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bd493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a39d2f89",
   "metadata": {},
   "source": [
    "# Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c4b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f2521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88601695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6c99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f66e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a3dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0237d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e4d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332f747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c307d87",
   "metadata": {},
   "source": [
    "# Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0728e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330c287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e34f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8d8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecdb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c76f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660fed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c01c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028de5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31568bfc",
   "metadata": {},
   "source": [
    "# Named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b43ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
