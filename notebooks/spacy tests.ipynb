{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-approach",
   "metadata": {},
   "source": [
    "# Sentencizer\n",
    "https://spacy.io/usage/linguistic-features#sbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "assert doc.has_annotation(\"SENT_START\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"../data/Original/iued_test_original.txt\"\n",
    "#name = \"../data/Original/iued_test_original.vrt\"\n",
    "with open (name, \"r\") as myfile:\n",
    "    data=myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be009395",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)\n",
    "assert doc.has_annotation(\"SENT_START\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd160d96",
   "metadata": {},
   "source": [
    "This gives somewhat accurate results, with some errors after numbers. You can also use a trained model, however this will not work on uncommon texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c37dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411fd346",
   "metadata": {},
   "source": [
    "Also fails for the example here. Then there is the one based on a statistical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.enable_pipe(\"senter\")\n",
    "doc = nlp(data)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f267e1c9",
   "metadata": {},
   "source": [
    "Directly use the sentencizer without the pipeline - this one looks at punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()  # just the language with no pipeline\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "doc = nlp(data)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('***')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6870a84",
   "metadata": {},
   "source": [
    "Seems to work correctly. What is the difference to the pipeline? In the DW scripts, the other components are disabled via the \"exclude\" command - should be faster as pipeline is not loaded at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for doc in nlp.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    # Do something with the doc here\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d629fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"tagger\", \"ner\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "for doc in nlp.pipe(texts):\n",
    "    for sent in doc.sents:\n",
    "        print(sent.text)\n",
    "        print('***') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d268fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
